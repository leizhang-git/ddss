# 项目相关配置
ddss:
  # 名称
  name: ddss
  # 版本
  version: 1.0.0
  # 版权年份
  copyrightYear: 2025
  # 文件路径 示例（ Windows配置D:/ruoyi/uploadPath，Linux配置 /home/ruoyi/uploadPath）
  profile: D:/ddss/uploadPath
  # 获取ip地址开关
  addressEnabled: false
  # 验证码类型 math 数字计算 char 字符验证
  captchaType: math

# 开发环境配置
server:
  # 服务器的HTTP端口，默认为8080
  port: 8088
  servlet:
    # 应用的访问路径
    context-path: /
  tomcat:
    # tomcat的URI编码
    uri-encoding: UTF-8
    # 连接数满后的排队数，默认为100
    accept-count: 1000
    threads:
      # tomcat最大线程数，默认为200
      max: 800
      # Tomcat启动初始化的线程数，默认值10
      min-spare: 100

# 日志配置
logging:
  level:
    com.ruoyi: debug
    org.springframework: warn

# 用户配置
user:
  password:
    # 密码最大错误次数
    maxRetryCount: 5
    # 密码锁定时间（默认10分钟）
    lockTime: 10

# Spring配置
spring:
  # 资源信息
  messages:
    # 国际化资源文件路径
    basename: i18n/messages
  # 文件上传
  servlet:
    multipart:
      # 单个文件大小
      max-file-size: 10MB
      # 设置总上传的文件大小
      max-request-size: 20MB
  # 服务模块
  devtools:
    restart:
      # 热部署开关
      enabled: true
  # redis 配置
  redis:
    # 哨兵模式核心配置
    sentinel:
      # 哨兵监控的主节点名称（必须和你配置的 mymaster 一致）
      master: mymaster
      # 哨兵节点地址（多个用逗号分隔）
      nodes: 192.168.145.100:26379,192.168.145.100:26380,192.168.145.100:26381
    # Redis 密码（和你配置的 123456 一致）
    password: 123456
    # 超时配置
    timeout: 10000ms
  kafka:
    producer:
      bootstrap-servers: 192.168.145.100:9092 #服务器地址
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all # 所有副本都确认才算写入成功，保证高可靠性
      retries: 3 # 发送失败时的重试次数
      batch-size: 16384 #批量发送的大小（字节）
      buffer-memory: 33554432 #生产者缓冲区大小（字节）
      compression-type: snappy  #消息压缩类型（none, gzip, snappy, lz4, zstd）
      properties:
        enable.idempotence: true  #启用幂等性，防止消息重复
        request.timeout.ms: 3000  #等待服务器响应的最大时间
        max.request.size: 1048576  #单个请求的最大大小
        linger.ms: 10 #延迟发送时间，等待更多消息一起发送（增加此值可以提高吞吐量，但会增加延迟）
        send.buffer.bytes: 131072 #TCP发送缓冲区大小
        receive.buffer.bytes: 32768 #TCP接收缓冲区大小
    #        max.block.ms: 60000 #发送阻塞的最大时间
    #        max.in.flight.requests.per.connection: 5  单个连接最大未确认请求数
    #      transaction-id-prefix: tx- #事务配置，不同的生产者必须使用不同的事务ID
    consumer:
      bootstrap-servers: 192.168.145.100:9092 #服务器地址
      group-id: ddss-server-group #消费者组id，同一组的消费者协同消费消息
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      enable-auto-commit: false #关闭自动提交，防止消息丢失
      max-poll-records: 500 #每次批量消费的最大消息数
      auto-offset-reset: latest #从最新的消息开始消费,保证消费者只处理最新的消息
      fetch-min-size: 1 #每次最小拉取大小，避免频繁拉取
      fetch-max-wait: 500 #当数据量不足fetch.min.bytes时，最多等待时间
      #      max-partition-fetch-bytes: 1048576  #每个分区返回的最大数据量
      #      fetch.max.bytes: 1048576  #一次请求中返回的最大数据量
      properties:
        session.timeout.ms: 45000 #消费者组会话超时时间，如果超过此时间没有心跳则认为消费者死亡
        max.poll.interval.ms: 300000  #两次poll之间的最大间隔，超过则认为消费者处理能力不足
        heatbeat.interval.ms: 3000  #心跳配置，心跳间隔时间，必须小于session.timeout.ms
    listener:
      ack-mode: MANUAL  #手动提交
      type: batch #开启批量消费模式，提高消费效率
      concurrency: 3  #消费者线程数
# token配置
token:
  # 令牌自定义标识
  header: Authorization
  # 令牌密钥
  secret: abcdefghijklmnopqrstuvwxyz
  # 令牌有效期（默认30分钟）
  expireTime: 30

# MyBatis配置
mybatis:
  # 搜索指定包别名
  typeAliasesPackage: com.ddss
  # 配置mapper的扫描，找到所有的mapper.xml映射文件
  mapperLocations: classpath*:mapper/**/*Mapper.xml
  # 加载全局的配置文件
  configLocation: classpath:mybatis/mybatis-config.xml

# PageHelper分页插件
pagehelper:
  helperDialect: mysql
  supportMethodsArguments: true
  params: count=countSql

# Swagger配置
swagger:
  # 是否开启swagger
  enabled: true
  # 请求前缀
  pathMapping: /dev-api

# 防盗链配置
referer:
  # 防盗链开关
  enabled: false
  # 允许的域名列表
  allowed-domains: localhost,127.0.0.1
# 白名单配置
whitelist:
  urls:
    - /login
    - /register
    - /captchaImage
    - /swagger-ui.html
    - /swagger-resources/**
    - /webjars/**
    - /*/api-docs
    - /druid/**
    - /profile/**
    - /
    - /*.html
    - /**/*.html
    - /**/*.css
    - /**/*.js
    - /test/**
    - /api/v1/ddss/test/**

# 防止XSS攻击
xss:
  # 过滤开关
  enabled: true
  # 排除链接（多个用逗号分隔）
  excludes: /system/notice
  # 匹配链接
  urlPatterns: /system/*,/monitor/*,/tool/*
mybatis-plus:
  # 实体扫描，多个package用逗号或者分号分隔
  type-aliases-package: com.ddss.server.domain.po
  # mapper.xml 文件位置
  mapper-locations: classpath*:/mapper/**/*.xml
  configuration:
    # 是否开启自动驼峰命名规则映射:从数据库列名到Java属性驼峰命名的类似映射
    map-underscore-to-camel-case: true
    # 这个配置会将执行的sql打印出来，在开发或测试的时候可以用
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
minio:
  endpoint: http://192.168.145.100:9000
  access-key: admin
  secret-key: 12345678
  bucket-name: app
  secure: false
# XXL-Job 配置
xxl:
  job:
    admin:
      # Admin 控制台地址（多个用逗号分隔，填你部署的 Admin 地址）
      addresses: http://192.168.145.100:8888/xxl-job-admin
    executor:
      # 执行器名称（自定义，会显示在 Admin 控制台）
      appname: ddss-executor
      # 执行器IP（默认自动获取，可不配）
      ip:
      # 执行器端口（自定义，避免冲突，如 9999）
      port: 9999
      # 执行器日志目录（和你 Admin 配置的日志路径对应）
      logpath: /data/applogs/xxl-job/jobhandler
      # 日志保存天数
      logretentiondays: 30
    # 访问令牌（和 Admin 控制台的 token 一致，默认空，若 Admin 配了需同步）
    accessToken:
kafka:
  producer:
    topic: ddss-producer-Topic
  consumer:
    topic: ddss-consumer-Topic
threadpool:
  # 是否开启线程
  open_flag: true
  # 核心线程数
  core_pool_size: 10
  # 最大线程数
  max_pool_size: 200
  # 队列大小
  queue_capacity: 400
  # 空闲线程活跃时间(s)
  keep_alive_seconds: 60
  # 线程池名称
  default_name: ddss-pool
  # 新增：拒绝策略（可选，生产环境建议加）
  rejection_policy: CallerRunsPolicy