package com.ddss.server.kafka;

import com.ddss.server.context.IContextInfoProxy;
import com.ddss.server.domain.KafkaMessage;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;
import org.springframework.stereotype.Component;

import javax.annotation.PostConstruct;
import javax.annotation.Resource;
import java.util.concurrent.Callable;
import java.util.concurrent.Future;

/**
 * @Auth zhanglei
 * @Date 2023/2/18 22:12
 */
@Configuration
@Component
public class KafkaProducer {

    private final Logger log = LoggerFactory.getLogger(KafkaProducer.class);

    @Autowired
    private KafkaTemplate<String,String> kafkaTemplate;

    @Resource
    private KafkaMessagePool kafkaMessagePool;

    private boolean isExit;

    @Resource
    private ThreadPoolTaskExecutor commonThreadPoolExecutor;

    @Value("${kafka.producer.topic}")
    private String producerTopic;
    // è®°å½•å¼‚æ­¥å‘é€ä»»åŠ¡çš„Futureï¼Œä¾¿äºå…³é—­æ—¶æ§åˆ¶
    private Future<?> sendFuture;

    @PostConstruct
    public void init() {
        // å¯åŠ¨å¼‚æ­¥å‘é€ä»»åŠ¡
        startAsyncSend();
        isExit = false;
    }

    /**
     * å¼‚æ­¥å‘é€æ¶ˆæ¯ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰
     */
    private void startAsyncSend() {
        // è°ƒç”¨ä½ æä¾›çš„executeæ–¹æ³•æäº¤ä»»åŠ¡
        sendFuture = execute(() -> {
            while (!isExit) {
                try {
                    KafkaMessage messages = kafkaMessagePool.getMessages();
                    if (messages != null) {
                        // å‘é€æ¶ˆæ¯åˆ°Kafkaï¼Œå¹¶ç›‘å¬å‘é€ç»“æœ
                        kafkaTemplate.send(producerTopic, messages.getKey(), messages.getData())
                                .addCallback(
                                        success -> log.info("Kafkaæ¶ˆæ¯å‘é€æˆåŠŸ ğŸ“¤ | ä¸»é¢˜ï¼š{} | Keyï¼š{} | Offsetï¼š{}",
                                                producerTopic, messages.getKey(), success.getRecordMetadata().offset()),
                                        failure -> log.error("Kafkaæ¶ˆæ¯å‘é€å¤±è´¥ âŒ | ä¸»é¢˜ï¼š{} | Keyï¼š{}",
                                                producerTopic, messages.getKey(), failure)
                                );
                    } else {
                        // æ— æ¶ˆæ¯æ—¶ä¼‘çœ 100msï¼Œé¿å…ç©ºè½®è¯¢æ¶ˆè€—CPU
                        Thread.sleep(100);
                    }
                } catch (InterruptedException e) {
                    log.warn("Kafkaå‘é€çº¿ç¨‹è¢«ä¸­æ–­", e);
                    Thread.currentThread().interrupt();
                } catch (Exception e) {
                    log.error("Kafkaå‘é€æ¶ˆæ¯å¼‚å¸¸", e);
                }
            }
            return null;
        });
    }

    /**
     * å¯¹å¤–æä¾›å‘é€å•ä¸ªæ¶ˆæ¯çš„æ–¹æ³•ï¼ˆä¾›XXL-Jobè°ƒç”¨ï¼‰
     */
    public void sendSingleMessage(KafkaMessage message) {
        if (message != null) {
            kafkaMessagePool.sendMessages(message);
            log.info("æ¶ˆæ¯å·²åŠ å…¥å‘é€é˜Ÿåˆ— | Keyï¼š{} | å†…å®¹ï¼š{}", message.getKey(), message.getData());
        }
    }

    public void close() {
        isExit = true;
        // å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
        if (sendFuture != null && !sendFuture.isDone()) {
            sendFuture.cancel(true);
        }
        log.info("Kafkaç”Ÿäº§è€…å¼‚æ­¥ä»»åŠ¡å·²å…³é—­");
    }

    // Getteræ–¹æ³•ï¼ˆä¾›XXL-Jobè·å–ç”Ÿäº§è€…ä¸»é¢˜ï¼‰
    public String getProducerTopic() {
        return producerTopic;
    }

    private Future<?> execute(Callable<?> loader){
        return commonThreadPoolExecutor.submit(()->{
            Object result;
            try {
                result = loader.call();
            }catch (Exception e){
                result = null;
            }finally {
                IContextInfoProxy.reset();
            }
            return result;
        });
    }
}
